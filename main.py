import os
import wave
import pyaudio
import keyboard
import pyperclip
import requests
from openai import OpenAI
from dotenv import load_dotenv
import tkinter as tk
import threading
import time

load_dotenv()
##########################
#     PARAM√àTRES AUDIO   #
##########################
CHUNK = 1024
FORMAT = pyaudio.paInt16
CHANNELS = 1          # mono
RATE = 44100
OUTPUT_FILENAME = "output.wav"

##########################
#   CL√â API OPENAI       #
##########################
# Soit dans la variable d'environnement :
client = OpenAI()

############################################
# 1) ANIMATION PENDANT L'ENREGISTREMENT   #
############################################
def show_recording_animation():
    """
    Affiche une fen√™tre visuellement agr√©able avec un point rouge anim√© et un chrono pendant l'enregistrement.
    """
    window = tk.Tk()
    window.title("Enregistrement en cours")
    window.geometry("300x150")
    window.configure(bg="#2C2F33")

    # Titre
    title_label = tk.Label(window, text="üî¥ Enregistrement...", fg="white", bg="#2C2F33", font=("Helvetica", 16, "bold"))
    title_label.pack(pady=10)

    # Animation de point rouge
    canvas = tk.Canvas(window, width=50, height=50, bg="#2C2F33", highlightthickness=0)
    canvas.pack()
    point = canvas.create_oval(10, 10, 40, 40, fill="red")

    # Chrono
    chrono_label = tk.Label(window, text="0:00", fg="white", bg="#2C2F33", font=("Helvetica", 14))
    chrono_label.pack(pady=10)

    def animate_point():
        while True:
            for i in range(5):
                canvas.move(point, 0, 2)
                window.update()
                time.sleep(0.05)
            for i in range(5):
                canvas.move(point, 0, -2)
                window.update()
                time.sleep(0.05)

    def update_timer():
        start_time = time.time()
        while True:
            elapsed_time = int(time.time() - start_time)
            minutes = elapsed_time // 60
            seconds = elapsed_time % 60
            chrono_label.config(text=f"{minutes}:{seconds:02}")
            time.sleep(1)

    threading.Thread(target=animate_point, daemon=True).start()
    threading.Thread(target=update_timer, daemon=True).start()

    window.mainloop()

############################################
# 2) ENREGISTRER L'AUDIO JUSQU'√Ä ESPACE    #
############################################
def record_audio_until_space(output_filename=OUTPUT_FILENAME):
    """
    Enregistre l'audio jusqu'√† ce que l'utilisateur appuie sur ESPACE.
    """
    audio = pyaudio.PyAudio()
    stream = audio.open(format=FORMAT, 
                        channels=CHANNELS,
                        rate=RATE,
                        input=True,
                        frames_per_buffer=CHUNK)

    print("=== Enregistrement en cours. Appuyez sur ESPACE pour arr√™ter. ===")
    frames = []

    # Lancer l'animation dans un thread s√©par√©
    animation_thread = threading.Thread(target=show_recording_animation, daemon=True)
    animation_thread.start()

    while True:
        data = stream.read(CHUNK)
        frames.append(data)
        
        if keyboard.is_pressed('space'):
            print("=== Espace d√©tect√©. Arr√™t de l'enregistrement. ===")
            break

    stream.stop_stream()
    stream.close()
    audio.terminate()

    with wave.open(output_filename, 'wb') as wf:
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(audio.get_sample_size(FORMAT))
        wf.setframerate(RATE)
        wf.writeframes(b''.join(frames))

############################################
# 3) TRANSCRIRE L'AUDIO (NOUVELLE API)     #
############################################
def transcribe_audio_with_whisper(filename=OUTPUT_FILENAME):
    """
    Utilise l'API Whisper d'OpenAI pour transcrire le fichier audio.
    Retourne la transcription sous forme de texte.
    """
    print("=== Transcription de l'audio via Whisper... ===")

    try:
        with open(filename, "rb") as audio_file:
            # Utilisation de la m√©thode correcte
            response = client.audio.transcriptions.create(
                file=audio_file,
                model="whisper-1"
            )
        text = response.text
        print("=== Transcription obtenue ===")
        print(text)
        return text
    except Exception as e:
        print(f"Erreur lors de la transcription : {e}")
        return ""

############################################
# 4) ENVOYER TEXTE √Ä GPT-4o              #
############################################
def send_to_gpt4o(prompt_text):
    """
    Envoie le 'prompt_text' √† GPT-4o.
    Retourne le texte de la r√©ponse.
    """
    print("=== Envoi √† ChatGPT (GPT-4o) ... ===")
    try:
        response = client.chat.completions.create(
            model="gpt-4o",  # Utilisation de GPT-4o
            messages=[
                {"role": "system", "content": "Tu es un assistant qui r√©pond en fran√ßais."},
                {"role": "user", "content": prompt_text}
            ]
        )
        answer = response.choices[0].message.content
        print("=== R√©ponse de ChatGPT ===")
        print(answer)
        return answer
    except Exception as e:
        print(f"Erreur lors de l'appel √† l'API ChatGPT: {e}")
        return ""

############################################
# 5) CODE PRINCIPAL                        #
############################################
if __name__ == "__main__":
    # 1) R√©cup√©ration du contenu du presse-papiers (avant l‚Äôenregistrement)
    clipboard_before = pyperclip.paste()
    print(f"=== Contenu actuel du presse-papiers ===\n{clipboard_before}\n")

    # 2) Enregistrer l'audio jusqu'√† la pression de la touche Espace
    record_audio_until_space()

    # 3) Transcrire le fichier audio via la nouvelle approche
    transcription_text = transcribe_audio_with_whisper(OUTPUT_FILENAME)

    # 4) Pr√©parer le texte √† envoyer √† GPT-4o:
    combined_prompt = (
        f"Contenu du presse-papiers:\n{clipboard_before}\n\n"
        f"Transcription de l'audio:\n{transcription_text}\n"
    )

    # 5) Envoyer √† GPT-4o et r√©cup√©rer la r√©ponse
    gpt4_response = send_to_gpt4o(combined_prompt)

    # 6) Copier la r√©ponse de GPT-4o dans le presse-papiers
    pyperclip.copy(gpt4_response)
    print("=== La r√©ponse de ChatGPT a √©t√© copi√©e dans le presse-papiers. ===")
